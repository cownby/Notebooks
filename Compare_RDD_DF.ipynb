{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test to Compare & Contrast RDD & Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SPARK_MASTER = 'local[*]'\n",
    "APPLICATION_NAME = 'explore'\n",
    "PYTHON_2_LOCATION = \"/usr/bin/python2.7\"\n",
    "DATAFILE = r'/home/jovyan/work/data/hamlet.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'2.0.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Explicitly define python 2 since we have both versions 2 & 3 installed\n",
    "os.environ[\"PYSPARK_PYTHON\"]=PYTHON_2_LOCATION\n",
    "\n",
    "# Create spark context with which we will reference the Spark API\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master(SPARK_MASTER)\n",
    "         .appName(APPLICATION_NAME)\n",
    "         .getOrCreate())\n",
    "\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method definition complete\n"
     ]
    }
   ],
   "source": [
    "# Word Count Methods \n",
    "\n",
    "import re\n",
    "import json\n",
    "from pyspark.sql.functions import regexp_replace, trim, col, lower, split,explode, desc\n",
    "\n",
    "def removePunctuationCol(aStr): \n",
    "    return trim(lower(regexp_replace(regexp_replace(aStr, '\\t', ' '), '[^ 0-9a-zA-Z]', '')))\n",
    "\n",
    "\n",
    "def wordCount_DF(datafile):\n",
    "\n",
    "    raw_df = spark.read.text(datafile)\n",
    "    words = (raw_df\n",
    "             .select(removePunctuationCol(col('value')).alias('value'))\n",
    "             .filter(col('value') != '')\n",
    "             .select(split(col('value'), ' ').alias('value'))\n",
    "             .select(explode('value').alias('word')).filter(col('word') != '')\n",
    "             .groupby('word').count()\n",
    "             .sort(desc('count'))\n",
    "            )\n",
    "    return str(words.toJSON().collect())\n",
    "\n",
    "\n",
    "\n",
    "def wordCount_RDD(datafile):\n",
    "\n",
    "    words_rdd = spark.sparkContext.textFile(datafile)\n",
    "    wordCount = (words_rdd\n",
    "                 .map(lambda line: re.sub(\"[\\t]\", ' ', line))\n",
    "                 .flatMap(lambda line: line.split(' '))\n",
    "                 .filter(lambda w: w != '')\n",
    "                 .map(lambda w: re.sub('[^a-z| |\\'|0-9]', '', w.strip().lower()))\n",
    "                 .map(lambda word: (word, 1))\n",
    "                 .reduceByKey(lambda a, b: a+b)\n",
    "                 .sortBy(lambda a: a[1],0)\n",
    "                 .map(lambda (a, b): {'word': a, 'count': str(b)})\n",
    "                )\n",
    "\n",
    "    return json.dumps(wordCount.collect())\n",
    "\n",
    "\n",
    "\n",
    "print 'Method definition complete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DF \n",
      "CPU times: user 108 ms, sys: 16 ms, total: 124 ms\n",
      "Wall time: 2.64 s\n",
      "[u'{\"word\":\"the\",\"count\":929}', u'{\"word\":\"and\",\"count\":842}', u'{\"word\":\"to\",\"count\":629}', u'{\"word\":\"of\",\"count\":562}', u'{\"word\":\"you\",\"count\":488}', u'{\"word\":\"i\",\"count\":463}', u'{\"word\":\"my\",\"c\n",
      "\n",
      " RDD \n",
      "CPU times: user 76 ms, sys: 0 ns, total: 76 ms\n",
      "Wall time: 694 ms\n",
      "[{\"count\": \"924\", \"word\": \"the\"}, {\"count\": \"841\", \"word\": \"and\"}, {\"count\": \"628\", \"word\": \"to\"}, {\"count\": \"562\", \"word\": \"of\"}, {\"count\": \"488\", \"word\": \"you\"}, {\"count\": \"442\", \"word\": \"i\"}, {\"cou\n"
     ]
    }
   ],
   "source": [
    "print '\\n DF '\n",
    "%time wc = wordCount_DF(DATAFILE)   \n",
    "print wc[:200] \n",
    "\n",
    "print '\\n RDD '\n",
    "%time wc = wordCount_RDD(DATAFILE) \n",
    "print wc[:200] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
